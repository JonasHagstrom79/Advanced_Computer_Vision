{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYrKX+XKX4QCNBYDjvRPTC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyMUzluz-qP-"
      },
      "outputs": [],
      "source": [
        "# Clone Tensorflow Models Repository\n",
        "!git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Protobuf\n",
        "# No need to do this if you are on Colab.\n",
        "\n",
        "# If you're doing this locally, download the latest Protobuf library for your OS from https://github.com/google/protobuf/releases\n",
        "\n",
        "# The filename should look like \"protoc--.zip\".\n",
        "\n",
        "# Assuming you've unzipped this zip file to \\<path>, the next step is to add \\<path>/bin to your PATH environment variable (on Linux or Mac).\n",
        "\n",
        "# Once Protobuf has been successfully installed, you can run the following command (note: must be done from the models/research folder).\n",
        "\n",
        "!cd models/research/ && protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "id": "uaQUfI_P_GQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the object detection API\n",
        "!cd models/research && \\\n",
        "    cp object_detection/packages/tf2/setup.py . && \\\n",
        "    python -m pip install ."
      ],
      "metadata": {
        "id": "WI6ndj3c_d9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Installation (Optional)\n",
        "!cd models/research && python object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "N50oiMO6_iGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import imageio\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "xP4-ZoSH_qvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "gsUXZTy0_vZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Videos\n",
        "!wget -nc https://lazyprogrammer.me/cnn_class2_videos.zip"
      ],
      "metadata": {
        "id": "eOTAO7T4_xTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip cnn_class2_videos.zip"
      ],
      "metadata": {
        "id": "kO7UO3HP_2Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "FBr0Owcd_4n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_VIDEOS = ['catdog', 'safari', 'traffic']"
      ],
      "metadata": {
        "id": "Tgj2NMRo_7RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and extract model files\n",
        "# Get URLs from the \"Object Detection Zoo\": https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
        "\n",
        "url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz'\n",
        "\n",
        "PATH_TO_MODEL_DIR = tf.keras.utils.get_file(\n",
        "    fname='ssd_resnet101_v1_fpn_640x640_coco17_tpu-8',\n",
        "    origin=url,\n",
        "    untar=True)"
      ],
      "metadata": {
        "id": "AQ9yb8R1_90e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_MODEL_DIR"
      ],
      "metadata": {
        "id": "EKXt9D3YAGT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Labels File\n",
        "# Label files can be found here: https://github.com/tensorflow/models/tree/master/research/object_detection/data\n",
        "\n",
        "# You probably won't need these since Object Detection Zoo contains only models trained on COCO.\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "\n",
        "PATH_TO_LABELS = tf.keras.utils.get_file(\n",
        "    fname='mscoco_label_map.pbtxt',\n",
        "    origin=url,\n",
        "    untar=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "TEzchI55AJhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_LABELS"
      ],
      "metadata": {
        "id": "IusnBpNyAV-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head {PATH_TO_LABELS}"
      ],
      "metadata": {
        "id": "wmEpyUnDAXyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the model\n",
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))"
      ],
      "metadata": {
        "id": "8br1iqsiAZaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the labels\n",
        "category_index = label_map_util.create_category_index_from_labelmap(\n",
        "    PATH_TO_LABELS,\n",
        "    use_display_name=True)"
      ],
      "metadata": {
        "id": "tSThiZu1Ab4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_index"
      ],
      "metadata": {
        "id": "wkWI-OxHAif6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do some object detection\n",
        "def detect_objects_in_image(image_np):\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # input_tensor = np.expand_dims(image_np, 0)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=200,\n",
        "          min_score_thresh=.30,\n",
        "          agnostic_mode=False)\n",
        "    return image_np_with_detections\n",
        "\n",
        "\n",
        "def detect_objects_in_video(input_video):\n",
        "    print(f'Running inference for {input_video}.mp4... ', end='')\n",
        "\n",
        "    video_reader = imageio.get_reader(f'{input_video}.mp4')\n",
        "    video_writer = imageio.get_writer(f'{input_video}_annotated.mp4', fps=10)\n",
        "\n",
        "    # loop through and process each frame\n",
        "    t0 = time.time()\n",
        "    n_frames = 0\n",
        "    for frame in video_reader:\n",
        "        n_frames += 1\n",
        "        new_frame = detect_objects_in_image(frame)\n",
        "\n",
        "        # instead of plotting image, we write the frame to video\n",
        "        video_writer.append_data(new_frame)\n",
        "\n",
        "    fps = n_frames / (time.time() - t0)\n",
        "    print(\"Frames processed: %s, Speed: %s fps\" % (n_frames, fps))\n",
        "\n",
        "    # clean up\n",
        "    video_writer.close()"
      ],
      "metadata": {
        "id": "yYhV43n-Aj-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_objects_in_video(INPUT_VIDEOS[0])"
      ],
      "metadata": {
        "id": "cxB5irfpApPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_objects_in_video(INPUT_VIDEOS[1])"
      ],
      "metadata": {
        "id": "uie8FOx3Arvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_objects_in_video(INPUT_VIDEOS[2])"
      ],
      "metadata": {
        "id": "BBLqIM5vAtjX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}