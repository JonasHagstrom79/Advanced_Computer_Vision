{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPloNyFyKd0QekP0J1l4HK+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tesorflow.keras.applications.resnet50 import ResNet50, preprocessing_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from glob import glob\n",
        "import itertools"
      ],
      "metadata": {
        "id": "1NbtO0w1Sdu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [100, 100] # can be chaged depending on dataset"
      ],
      "metadata": {
        "id": "NC7ltX3ETRsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sxJ-fG7OTZ2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "s9G7IFXjNVoD",
        "outputId": "7c60b23f-eb6b-4a93-ada1-edee88cea529"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7071353c3b3a>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_is_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../large_files/fruits-360-small'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-7071353c3b3a>\u001b[0m in \u001b[0;36mmkdir\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../large_files/fruits-360-small'"
          ]
        }
      ],
      "source": [
        "# https://deeplearningcourses.com/c/advanced-computer-vision\n",
        "# https://www.udemy.com/advanced-computer-vision\n",
        "import os\n",
        "\n",
        "def mkdir(p):\n",
        "  if not os.path.exists(p):\n",
        "    os.mkdir(p)\n",
        "\n",
        "def link(src, dst):\n",
        "  if not os.path.exists(dst):\n",
        "    os.symlink(src, dst, target_is_directory=True)\n",
        "\n",
        "mkdir('../large_files/fruits-360-small')\n",
        "\n",
        "\n",
        "classes = [\n",
        "  'Apple Golden 1',\n",
        "  'Avocado',\n",
        "  'Lemon',\n",
        "  'Mango',\n",
        "  'Kiwi',\n",
        "  'Banana',\n",
        "  'Strawberry',\n",
        "  'Raspberry'\n",
        "]\n",
        "\n",
        "train_path_from = os.path.abspath('../large_files/fruits-360/Training')\n",
        "valid_path_from = os.path.abspath('../large_files/fruits-360/Validation')\n",
        "\n",
        "train_path_to = os.path.abspath('../large_files/fruits-360-small/Training')\n",
        "valid_path_to = os.path.abspath('../large_files/fruits-360-small/Validation')\n",
        "\n",
        "mkdir(train_path_to)\n",
        "mkdir(valid_path_to)\n",
        "\n",
        "\n",
        "for c in classes:\n",
        "  link(train_path_from + '/' + c, train_path_to + '/' + c)\n",
        "  link(valid_path_from + '/' + c, valid_path_to + '/' + c)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://deeplearningcourses.com/c/advanced-computer-vision\n",
        "# https://www.udemy.com/advanced-computer-vision\n",
        "from __future__ import print_function, division\n",
        "from builtins import range, input\n",
        "# Note: you may need to update your version of future\n",
        "# sudo pip install -U future\n",
        "\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "\n",
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [100, 100] # feel free to change depending on dataset\n",
        "\n",
        "# training config:\n",
        "epochs = 5\n",
        "batch_size = 32\n",
        "\n",
        "# https://www.kaggle.com/paultimothymooney/blood-cells\n",
        "# train_path = '../large_files/blood_cell_images/TRAIN'\n",
        "# valid_path = '../large_files/blood_cell_images/TEST'\n",
        "\n",
        "# https://www.kaggle.com/moltean/fruits\n",
        "train_path = '../large_files/fruits-360/Training'\n",
        "valid_path = '../large_files/fruits-360/Validation'\n",
        "# train_path = '../large_files/fruits-360-small/Training'\n",
        "# valid_path = '../large_files/fruits-360-small/Validation'\n",
        "\n",
        "# useful for getting number of files\n",
        "image_files = glob(train_path + '/*/*.jp*g')\n",
        "valid_image_files = glob(valid_path + '/*/*.jp*g')\n",
        "\n",
        "# useful for getting number of classes\n",
        "folders = glob(train_path + '/*')\n",
        "\n",
        "\n",
        "# look at an image for fun\n",
        "plt.imshow(image.img_to_array(image.load_img(np.random.choice(image_files))).astype('uint8'))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# add preprocessing layer to the front of VGG\n",
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "\n",
        "# don't train existing weights\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# our layers - you can add more if you want\n",
        "x = Flatten()(vgg.output)\n",
        "# x = Dense(1000, activation='relu')(x)\n",
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=vgg.input, outputs=prediction)\n",
        "\n",
        "# view the structure of the model\n",
        "model.summary()\n",
        "\n",
        "# tell the model what cost and optimization method to use\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='rmsprop',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "# create an instance of ImageDataGenerator\n",
        "gen = ImageDataGenerator(\n",
        "  rotation_range=20,\n",
        "  width_shift_range=0.1,\n",
        "  height_shift_range=0.1,\n",
        "  shear_range=0.1,\n",
        "  zoom_range=0.2,\n",
        "  horizontal_flip=True,\n",
        "  vertical_flip=True,\n",
        "  preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "\n",
        "# test generator to see how it works and some other useful things\n",
        "\n",
        "# get label mapping for confusion matrix plot later\n",
        "test_gen = gen.flow_from_directory(valid_path, target_size=IMAGE_SIZE)\n",
        "print(test_gen.class_indices)\n",
        "labels = [None] * len(test_gen.class_indices)\n",
        "for k, v in test_gen.class_indices.items():\n",
        "  labels[v] = k\n",
        "\n",
        "# should be a strangely colored image (due to VGG weights being BGR)\n",
        "for x, y in test_gen:\n",
        "  print(\"min:\", x[0].min(), \"max:\", x[0].max())\n",
        "  plt.title(labels[np.argmax(y[0])])\n",
        "  plt.imshow(x[0])\n",
        "  plt.show()\n",
        "  break\n",
        "\n",
        "\n",
        "# create generators\n",
        "train_generator = gen.flow_from_directory(\n",
        "  train_path,\n",
        "  target_size=IMAGE_SIZE,\n",
        "  shuffle=True,\n",
        "  batch_size=batch_size,\n",
        ")\n",
        "valid_generator = gen.flow_from_directory(\n",
        "  valid_path,\n",
        "  target_size=IMAGE_SIZE,\n",
        "  shuffle=True,\n",
        "  batch_size=batch_size,\n",
        ")\n",
        "\n",
        "\n",
        "# fit the model\n",
        "r = model.fit(\n",
        "  train_generator,\n",
        "  validation_data=valid_generator,\n",
        "  epochs=epochs,\n",
        "  steps_per_epoch=len(image_files) // batch_size,\n",
        "  validation_steps=len(valid_image_files) // batch_size,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "def get_confusion_matrix(data_path, N):\n",
        "  # we need to see the data in the same order\n",
        "  # for both predictions and targets\n",
        "  print(\"Generating confusion matrix\", N)\n",
        "  predictions = []\n",
        "  targets = []\n",
        "  i = 0\n",
        "  for x, y in gen.flow_from_directory(data_path, target_size=IMAGE_SIZE, shuffle=False, batch_size=batch_size * 2):\n",
        "    i += 1\n",
        "    if i % 50 == 0:\n",
        "      print(i)\n",
        "    p = model.predict(x)\n",
        "    p = np.argmax(p, axis=1)\n",
        "    y = np.argmax(y, axis=1)\n",
        "    predictions = np.concatenate((predictions, p))\n",
        "    targets = np.concatenate((targets, y))\n",
        "    if len(targets) >= N:\n",
        "      break\n",
        "\n",
        "  cm = confusion_matrix(targets, predictions)\n",
        "  return cm\n",
        "\n",
        "\n",
        "cm = get_confusion_matrix(train_path, len(image_files))\n",
        "print(cm)\n",
        "valid_cm = get_confusion_matrix(valid_path, len(valid_image_files))\n",
        "print(valid_cm)\n",
        "\n",
        "\n",
        "# plot some data\n",
        "\n",
        "# loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# accuracies\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "from util import plot_confusion_matrix\n",
        "plot_confusion_matrix(cm, labels, title='Train confusion matrix')\n",
        "plot_confusion_matrix(valid_cm, labels, title='Validation confusion matrix')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "jHIu84ncN77f",
        "outputId": "1810320b-bb52-40e8-b120-9a99d42b2f32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1ba5c2305809>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# look at an image for fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.preprocessing.image' has no attribute 'img_to_array'"
          ]
        }
      ]
    }
  ]
}